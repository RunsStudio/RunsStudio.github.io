<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Graph WaveNet - 学习笔记</title>
    <link href="/2025/05/06/Graph%20WaveNet%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <url>/2025/05/06/Graph%20WaveNet%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<p>【论文地址】：<a href="https://arxiv.org/pdf/1906.00121.pdf">https://arxiv.org/pdf/1906.00121.pdf</a><br>【代码地址】：github.com&#x2F;nnzhan&#x2F;Graph-WaveNet</p><p>论文摘要<br>动机：时空图建模是分析时间关系和空间关系的重要任务，过去的方法大多数都是从固定的图结构上提取空间依赖性，假设实体之间的基本关系是预先确定的。但是，显式的图结构不一定反应真实的以来关系，而且由于数据中连接不完整，可能缺少真正的关系。RNN和CNN又有各自的缺陷，无法捕捉长时间的序列，因此，该文章提出一种新的图神经网络架构Graph WaveNet用于时空图建模，通过开发一种新的自适应依赖关系矩阵，并通过节点嵌入的方式来进行学习。该模型可以捕捉数据中隐藏的空间以来关系，借助堆叠的膨胀1-D卷积，能够随着层数增加感受到宽广的感受野，从而处理非常长的序列。<br>该论文主要用于解决时空建模问题上图结构不确定性问题，通过自适应的可学习的邻接矩阵从数据中自动学习图结构，该论文是基于wavenet网络改进的。<br>论文主要思路：<br>时空图建模背后的一个基本假设是：一个节点的未来信息取决于它的历史信息以及它邻居节点的历史信息。但是这种模型存在两个主要的缺点：</p><ul><li><p>显式的图结构不能充分的反应真实的依赖关系（空间）：</p><ul><li>连接不需要两个节点之间的相互依赖关系</li><li>两个节点之间的相互依赖关系存在但连接缺失</li></ul></li><li><p>时空图不能有效地学习时间依赖关系（时间）：</p><ul><li>基于RNN的方法在捕获长序列时存在耗时的迭代传播和梯度爆炸&#x2F;消失现象；</li><li>基于CNN的方法具有并行计算、稳定梯度和低内存需求等优点。 然而，由于采用标准的一维卷积，其感受野大小随隐藏层数的增加而线性增长，因此需要使用许多层才能捕获很长的序列。<br>问题定义<br>交通预测问题，可以认为是给定一张图<br>[图片]<br>其中V是节点，E是边，交通预测问题可以描述为：<br>[图片]<br>式中：<br>[图片]<br>分别表示X个特征在过去T个时刻的值（流量变化情况），这里N是节点数，D是数据维数，T是时间步，简单来说就是用过去的S步预测未来的T步。<br> 空间卷积<br>GCN时代：<br>[图片]<br>其中要求邻接矩阵A已知，实际上很多情况下，A可能是变化的，或者存在未能被挖掘到的节点，对当前节点存在影响。文章不用传统的GCN，而是用了扩散的卷积层，形式如下：<br>[图片]<br>式中：Pk代表是转移矩阵的k次乘方，K的次数是可以改变的，X是原来的特征，对于无向图，P&#x3D;A&#x2F;rowsum(A)，对于有向图，区分正反向，正向是Pf&#x3D;A&#x2F;rowsum（A），反向是Pb&#x3D;At &#x2F;rowsum(A_T)<br>从而扩散图卷积层款可以写成式4的形式。</li></ul></li></ul><p>文章同时提出一种自适应邻接矩阵的概念，这种矩阵不需要任何先验知识，而且是可以从端到端的方式进行梯度下降训练。可以表示成：<br>[图片]<br>这里面，E1 E2是两个科学系的Embedding矩阵，案例来说应该就是原始输入X乘了一个Embedding矩阵之后得到的。。那么这个公式，岂不就是自注意力嘛<br>[图片]<br>（自注意力的计算公式，Q Kt分别对应这里的E1 E2）区别在于文章这里加了个Relu （这是GAT的做法）只关注对当前节点正向的内容。<br>所以，在图已知的情况下，可以用式6的方式计算 图卷积，如果是图未知的情况下，就用图7计算<br>[图片]<br>文章提到：值得注意的是，我们的图卷积属于基于空间的方法。尽管为了保持一致性，我们将图信号与节点特征矩阵互换使用，但我们在方程 7 中的图卷积确实被解释为聚合来自不同邻域顺序的转换特征信息。<br>时间卷积层<br>时间卷积文章采用了 空洞因果卷积 作为时间卷积层（TCN），空洞卷积神经网络能够以非递归的方式处理长距离序列。公式可以描述成：<br>[图片]<br>[图片]</p><p>参考文献：<br><a href="http://zhuanlan.zhihu.com/p/594429261">http://zhuanlan.zhihu.com/p/594429261</a></p>]]></content>
    
    
    <categories>
      
      <category>时空图</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>STIDGCN - 学习笔记</title>
    <link href="/2025/04/28/STIDGCN%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <url>/2025/04/28/STIDGCN%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="STIDGCN-学习笔记"><a href="#STIDGCN-学习笔记" class="headerlink" title="STIDGCN - 学习笔记"></a>STIDGCN - 学习笔记</h1><h2 id="1-文章摘要"><a href="#1-文章摘要" class="headerlink" title="1. 文章摘要"></a>1. 文章摘要</h2><p>准确的交通预测对于城市交通管理、路线规划和流量检测至关重要。时空模型的最新进展显着改进了交通预测中复杂的时空相关性的建模。不幸的是，之前的大多数研究在跨不同感知视角有效建模时空相关性方面遇到了挑战，并且忽略了时空相关性之间的交互学习。此外，受空间异质性的限制，大多数研究未能考虑每个节点不同的时空模式。为了克服这些限制，我们提出了一种用于流量预测的时空交互式动态图卷积网络（STIDGCN）。具体来说，文章提出了一个由空间和时间模块组成的交互式学习框架，用于对流量数据进行下采样。该框架旨在通过采用从全局到局部的感知视角来捕捉空间和时间的相关性，并通过积极的反馈促进它们的相互利用。在空间模块中，我们基于图构造方法设计了动态图卷积网络。该网络旨在利用考虑时空异质性的流量模式库作为查询来重建数据驱动的动态图结构。重构的图结构可以揭示交通网络中节点之间的动态关联。对八个真实世界流量数据集的大量实验表明，STIDGCN  在平衡计算成本的同时优于最先进的基线。</p><p>源代码：<br><a href="https://github.com/LiuAoyu1998/STIDGCN/blob/main/model.py">源代码</a></p><p>论文：<br><a href="https://ieeexplore.ieee.org/abstract/document/10440184">论文</a></p><h2 id="2-模型核心结构"><a href="#2-模型核心结构" class="headerlink" title="2. 模型核心结构"></a>2. 模型核心结构</h2><p><img src="/2025/04/28/STIDGCN%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image0.png" alt="核心结构"></p><ul><li>STI结构把输入分成多个序列，并且向下游不断分裂，形成类似二叉树的结构。这样做的目的：类似时序卷积，例如原始序列id：12345，分裂后序列A就是135，B就是246，这样序列A就能侧重分析到索引1和3之间的关系，如果原始数据是五分钟级别的，做一次STI可以认为变成关注十分钟级别的，两次就是关注二十分钟级别的。</li><li>创新点：创新了一个DGCN模块，把原始序列分成奇序列（<img src="/2025/04/28/STIDGCN%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image.png" alt="奇数序列">）和偶序列<img src="/2025/04/28/STIDGCN%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-1.png" alt="偶数序列">，送入时序卷积块中提取卷积信息，然后送到DGCN块中提取空间信息。最重要的一点是是<strong>交互学习</strong>，也就是看图中的红线，奇序列经过图模块提取完空间信息后的隐向量将会与偶序列进行哈德马积（红线、绿线），反过来偶数序列时序卷积、DGCN后也和奇序列进行哈德玛积。这个过程会进行两次，因此形成一个时空交互的结构，这个过程是本文最大的创新点。</li></ul><h2 id="3-各模块介绍"><a href="#3-各模块介绍" class="headerlink" title="3. 各模块介绍"></a>3. 各模块介绍</h2><h3 id="3-1-Encoder"><a href="#3-1-Encoder" class="headerlink" title="3.1 Encoder"></a>3.1 Encoder</h3><p><strong>TSConv模块</strong> 用来捕捉时间的序列相关性<br>是二维的CNN，使用kernel（1，s1,）、（1，s2），s1、s2是预先定义好的核尺寸。TSConv可与定义为如下公式：<br><img src="/2025/04/28/STIDGCN%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-2.png" alt="卷积公式"></p><p>其中H_t 和 H_t’ 代表了TSConv的隐状态，这里省略了激活函数。<br>通过两层的卷积，能够提取到单个序列上的时序的动态性</p><p><strong>DGCN模块</strong> 用来捕捉空间动态相关性<br>因为文章处理的是动态图，预先不知道图的邻接矩阵，得通过DGCN结构提取空间状态表征<br>分成两个步骤：<br>①动态图重构：模拟动态的邻接矩阵<br>②对于构建的动态图，聚合周边节点的信息<br>输入是TSConv模块学习后的嵌入表示，这里输入的维度是Hg∈R（C×N×t’），C表示隐藏层的维度，channel，N是节点的个数，t’是时序的长度。<br>这里由于输入的 尺寸不一样，因此先经过一个全连接层，得到聚合输入Hf ∈R（C×N），随后和模式库（φ，Pattern Bank）进行交叉注意力（Hf和φ，得到Ap）和自注意力（Hf和Hf，得到Ah）计算。这里Pattern Bank是一个可训练的矩阵，φ∈R（C×N），可以认为是一种节点嵌入。，进行 交叉注意力和自注意力计算公式如下：<br> <img src="/2025/04/28/STIDGCN%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-3.png" alt="注意力计算公式"><br>如此操作后，会得到两个邻接矩阵，Ap和Ah，这是两个矩阵，大小都是N×N<br>然后把两个邻接矩阵拼起来（Concat）操作，得到一个2N×N的操作，为了和下游的尺度对齐，又经过一个全连接层，这一步的目的是把矩阵的尺度从N×2N变成N×N<br> <img src="/2025/04/28/STIDGCN%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-4.png" alt="全连接层公式"><br>得到了Af之后，可以认为Af中包含了节点和节点之间的关系，这是一个N×N的矩阵，可以认为是包含了图注意力的邻接矩阵，实际上图里节点之间不是所有节点都连接在一起的。还需要屏蔽掉不相关的节点。文章是对Af与矩阵M进行哈德玛积，矩阵M可以认为是注意力里面的Mask，取得是一个节点与他最相邻的K个邻居，通过Top-K的方式选取。（更通俗来说，一个节点i分别和各个节点计算相关性，最相关的K个节点标记1，否则标记0.）<br> <img src="/2025/04/28/STIDGCN%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-5.png" alt="节点相关性的定义"><br>得到邻接矩阵就可以进行图卷积操作了，文章采用扩散GCN进行动态图卷积，扩散图卷积把节点的动态变化描述成一个“扩散”过程，扩散图卷积聚合了图中节点之间的信息。扩散信号院子目标节点和当前最近的节点。扩散GCN可以描述为：<br> <img src="/2025/04/28/STIDGCN%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-6.png" alt="扩散GCN"><br>这里的Hg就是最开始的TSConv表征后的隐向量，尺寸是C×N×t’，W 是自学习权重的矩阵，尺寸是N×N，Af是刚刚得到的邻接矩阵，大小N×N。这个地方矩阵乘的维度没有写的很清楚，纳闷了很久维度不一样怎么乘，看代码，我们可以看到矩阵相乘是在N维度上相乘，最终输出还是B×C×N×T（TODO，这里可以单独实验一下DGCN模块的输入、输出）。<br> <img src="/2025/04/28/STIDGCN%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-7.png" alt="截图来自：https:&#x2F;&#x2F;github.com&#x2F;LiuAoyu1998&#x2F;STIDGCN&#x2F;blob&#x2F;main&#x2F;model.py"></p><p><strong>时空交互学习</strong><br>最终整个交互学习的过程，用公式的话可以描述成，和首图是对得上的：<br> <img src="/2025/04/28/STIDGCN%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-8.png" alt="交互学习过程"></p><h3 id="3-2-Decoder"><a href="#3-2-Decoder" class="headerlink" title="3.2 Decoder"></a>3.2 Decoder</h3><p>解码器的作用是输入编码器的编码后的特征He，对应表征学习后的是隐向量，经过两层FC和门控单元（可以理解就是控制信息的流入量），通过解码后得到最终的预测结果<br><img src="/2025/04/28/STIDGCN%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-9.png" alt="解码器结构"></p><h2 id="4-实验"><a href="#4-实验" class="headerlink" title="4. 实验"></a>4. 实验</h2><h3 id="4-1-对比实验"><a href="#4-1-对比实验" class="headerlink" title="4.1 对比实验"></a>4.1 对比实验</h3><p>模型采用了PEMS多个数据集，在多个数据集上进行测试，取得了SOTA的效果。</p><p><img src="/2025/04/28/STIDGCN%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-10.png" alt="评测结果"></p><p>评价指标选的是MAE,MAPE,RMSE</p><h3 id="4-2-消融实验"><a href="#4-2-消融实验" class="headerlink" title="4.2 消融实验"></a>4.2 消融实验</h3><p>（待补充）</p>]]></content>
    
    
    <categories>
      
      <category>时空图</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>多模态表征学习 - 学习笔记</title>
    <link href="/2025/04/23/%E8%A1%A8%E5%BE%81%E5%AD%A6%E4%B9%A0/"/>
    <url>/2025/04/23/%E8%A1%A8%E5%BE%81%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="1-表征学习的定义、分类和发展趋势"><a href="#1-表征学习的定义、分类和发展趋势" class="headerlink" title="1.表征学习的定义、分类和发展趋势"></a>1.表征学习的定义、分类和发展趋势</h1><h2 id="1-1-表征学习的定义"><a href="#1-1-表征学习的定义" class="headerlink" title="1.1 表征学习的定义"></a>1.1 表征学习的定义</h2><p><strong>表征学习的定义</strong>：表征学习（Representation Learning）是一种通过算法从数据中自动学习到有用特征的技术，其目的是将复杂的、高维的原始数据转化为机器学习能够高效处理的低维特征表示。表征学习对应的是经典机器学习中的“特征提取”模块，过往常常通过人工去提取特征，表征学习则将此过程自动化，通过机器学习算法处理。<br><strong>表征学习的模型输入</strong>：原始数据，其中包含高维度特征，例如：图像、文字、音频、视频、图等结构化或非结构化的数据<br><strong>表征学习输出</strong>：经过表征学习之后，提取出能被下游任务使用的低维特征。这里的特征可以是显式的也可以是隐式的。目前主流的技术路线是将表征层作为上游任务预训练，学习完成之后向下游任务传递隐式信息。模型的下游任务可以是分类、预测、生成式任务。</p><p><img src="/2025/04/23/%E8%A1%A8%E5%BE%81%E5%AD%A6%E4%B9%A0/%E5%A4%9A%E6%A8%A1%E6%80%81%E8%A1%A8%E5%BE%81.png" alt="多模态表征学习实例之Gemini模型架构"></p><h2 id="1-2-表征学习的分类"><a href="#1-2-表征学习的分类" class="headerlink" title="1.2 表征学习的分类"></a>1.2 表征学习的分类</h2><p>表征学习按照任务划分，可以划分为：</p><ul><li><p>文字表征</p><ul><li>核心：对文本进行表征，即自然语言符号信息表示成数字信息，方便下游任务处理</li><li>经典方法<ul><li>Word2Vec（Word Embedding）</li><li>Bert（Deep Model）</li></ul></li></ul></li><li><p>视觉表征</p><ul><li>核心：理解各种视觉图像数据（如照片、医学图像、文件扫描、视频流）等的语义</li><li>经典方法<ul><li>Vgg-16、 ResNet（CNN系）</li><li>MAE、VIT（Transformer系）</li></ul></li></ul></li><li><p>音频表征</p><ul><li>核心：从音频信号中提取对应的声音特征</li><li>经典方法<ul><li>Wav2Vec</li><li>SimCLR</li><li>MAE</li></ul></li></ul></li><li><p>图表征</p><ul><li>核心：将图数据映射到向量空间，以保留图的结构特征和语义特征</li><li>经典方法<ul><li>GCN</li><li>GAT</li></ul></li></ul></li><li><p>多模态表征</p><ul><li>核心：旨在融合多种数据模态（如：文本、图像、音频、视频等）来提高模型的感知与理解能力，实现跨模态信息的交互与融合</li><li>经典方法<ul><li>预训练：BEIT、MAE</li><li>语义对齐：BLIP、CLIP、BEIT等</li><li>大模型：GPT、Gemini等</li></ul></li></ul></li></ul><h2 id="1-3-表征学习的发展趋势"><a href="#1-3-表征学习的发展趋势" class="headerlink" title="1.3 表征学习的发展趋势"></a>1.3 表征学习的发展趋势</h2><h3 id="2018年以前：以CNN-RNN-DNN架构为主"><a href="#2018年以前：以CNN-RNN-DNN架构为主" class="headerlink" title="2018年以前：以CNN&#x2F;RNN&#x2F;DNN架构为主"></a>2018年以前：以CNN&#x2F;RNN&#x2F;DNN架构为主</h3><ul><li>AlexNet  【图像】</li><li>Vgg16  【图像】</li><li>ResNet  【图像】</li><li>Word2Vec 【文字】</li><li>GCN 【图】</li></ul><h3 id="2018-2023：-Transformer架构逐渐成为主流框架、"><a href="#2018-2023：-Transformer架构逐渐成为主流框架、" class="headerlink" title="2018-2023： Transformer架构逐渐成为主流框架、"></a>2018-2023： Transformer架构逐渐成为主流框架、</h3><ul><li>BERT 【文】</li><li>ViT 【图像】</li><li>GAT&#x2F;Graph Transformer 【图】</li><li>MAE 【图像&#x2F;视频】</li><li>CLIP 【图像】</li><li>VILT 【图像】</li></ul><h3 id="2023后：-与大模型架构相结合（所列出的模型全部属于多模态大模型）"><a href="#2023后：-与大模型架构相结合（所列出的模型全部属于多模态大模型）" class="headerlink" title="2023后： 与大模型架构相结合（所列出的模型全部属于多模态大模型）"></a>2023后： 与大模型架构相结合（所列出的模型全部属于多模态大模型）</h3><ul><li>Grok3</li><li>Qwen-VL</li><li>GPT-4o</li><li>Gemini</li><li>Deepseek-VL</li><li>LLAVA-NeXT</li><li>Mini-GPT</li><li>Doubao - 1.5</li><li>Cosmos</li></ul><h3 id="技术发展趋势："><a href="#技术发展趋势：" class="headerlink" title="技术发展趋势："></a>技术发展趋势：</h3><ul><li>小模型专注于计算机视觉、文字处理等机器学习经典领域，聚焦人脸识别、目标检测等专业任务</li><li>大模型时代多模态表征是标配，聚焦多模态理解（语义对齐、协同学习）与多模态生成方向</li><li>图像+文字+视频的多模态融合是主要研究方向，主要需要解决语义对齐、语义融合与协同学习的问题。</li></ul><h1 id="2-表征学习的主流架构"><a href="#2-表征学习的主流架构" class="headerlink" title="2. 表征学习的主流架构"></a>2. 表征学习的主流架构</h1><h2 id="2-1-图像表征经典架构———CNN结构"><a href="#2-1-图像表征经典架构———CNN结构" class="headerlink" title="2.1 图像表征经典架构———CNN结构"></a>2.1 图像表征经典架构———CNN结构</h2><p>说到表征就不得不说到CNN，关于CNN的结构就不多介绍了。我们在此思考，为什么CNN模型在CV领域取得了巨大的成功？<br>主要有以下几点原因：</p><ul><li><strong>感知性</strong>： 卷积层通过卷积操作和参数共享，能够提取图像的局部特征</li><li><strong>参数共享</strong>：相同的卷积核在不同的位置对图像进行卷积操作，共享参数减少了模型的复杂度，也增强了模型的泛化能力</li><li><strong>空间不变性</strong>：卷积操作具有平移不变性，即无论图像中的物体在图像中的位置如何变化，比如上下左右平移，最终都能被卷积核扫到，能够提取到相应的特征。</li></ul><p>例如 可以到<a href="https://poloclub.github.io/cnn-explainer/">卷积可视化网站</a>查看卷积操作都对图片做了什么。可以看到，浅层卷积分辨率高，提取点、颜色等基础特征，随着卷积的深入，逐渐提取到线段、边缘、轮廓、角点等特征，进行多层卷积之后的图像具有分辨率低的特点，从而能够和最终分类的抽象特征强相关联。这就是CNN模型起效的原因。<br><img src="/2025/04/23/%E8%A1%A8%E5%BE%81%E5%AD%A6%E4%B9%A0/image1.gif" alt="卷积操作可视化"></p><h2 id="2-2-图像表征改进架构———Transformer结构"><a href="#2-2-图像表征改进架构———Transformer结构" class="headerlink" title="2.2 图像表征改进架构———Transformer结构"></a>2.2 图像表征改进架构———Transformer结构</h2><h2 id="2-3-Transformer架构讨论分析"><a href="#2-3-Transformer架构讨论分析" class="headerlink" title="2.3 Transformer架构讨论分析"></a>2.3 Transformer架构讨论分析</h2><h1 id="3-多模态表征与多模态大模型"><a href="#3-多模态表征与多模态大模型" class="headerlink" title="3. 多模态表征与多模态大模型"></a>3. 多模态表征与多模态大模型</h1><h2 id="3-1-多模态表征的定义、动机和核心问题"><a href="#3-1-多模态表征的定义、动机和核心问题" class="headerlink" title="3.1 多模态表征的定义、动机和核心问题"></a>3.1 多模态表征的定义、动机和核心问题</h2><h2 id="3-2-多模态表征的经典结构"><a href="#3-2-多模态表征的经典结构" class="headerlink" title="3.2 多模态表征的经典结构"></a>3.2 多模态表征的经典结构</h2><h3 id="3-2-1-单塔结构（以VILT为例）"><a href="#3-2-1-单塔结构（以VILT为例）" class="headerlink" title="3.2.1 单塔结构（以VILT为例）"></a>3.2.1 单塔结构（以VILT为例）</h3><h3 id="3-2-2-双塔结构（以CLIP为例）"><a href="#3-2-2-双塔结构（以CLIP为例）" class="headerlink" title="3.2.2 双塔结构（以CLIP为例）"></a>3.2.2 双塔结构（以CLIP为例）</h3><h2 id="3-3-多模态大模型"><a href="#3-3-多模态大模型" class="headerlink" title="3.3 多模态大模型"></a>3.3 多模态大模型</h2><h3 id="3-3-1-多模态大模型的通用结构"><a href="#3-3-1-多模态大模型的通用结构" class="headerlink" title="3.3.1 多模态大模型的通用结构"></a>3.3.1 多模态大模型的通用结构</h3><h1 id="4-时空图表征"><a href="#4-时空图表征" class="headerlink" title="4. 时空图表征"></a>4. 时空图表征</h1><h2 id="4-1-交通场景下的表征学习"><a href="#4-1-交通场景下的表征学习" class="headerlink" title="4.1 交通场景下的表征学习"></a>4.1 交通场景下的表征学习</h2><h2 id="4-2-时空图的定义"><a href="#4-2-时空图的定义" class="headerlink" title="4.2 时空图的定义"></a>4.2 时空图的定义</h2><h2 id="4-3-图表征的经典框架（GCN、GAT）"><a href="#4-3-图表征的经典框架（GCN、GAT）" class="headerlink" title="4.3 图表征的经典框架（GCN、GAT）"></a>4.3 图表征的经典框架（GCN、GAT）</h2><h2 id="4-4-时空图表征经典模型（STGCN）"><a href="#4-4-时空图表征经典模型（STGCN）" class="headerlink" title="4.4 时空图表征经典模型（STGCN）"></a>4.4 时空图表征经典模型（STGCN）</h2><h2 id="4-5-时空图表征与信号控制相结合的案例（CoLight、STLight）"><a href="#4-5-时空图表征与信号控制相结合的案例（CoLight、STLight）" class="headerlink" title="4.5 时空图表征与信号控制相结合的案例（CoLight、STLight）"></a>4.5 时空图表征与信号控制相结合的案例（CoLight、STLight）</h2><h1 id="5-参考文献"><a href="#5-参考文献" class="headerlink" title="5. 参考文献"></a>5. 参考文献</h1>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch快速入门笔记</title>
    <link href="/2025/04/02/Pytorch%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/"/>
    <url>/2025/04/02/Pytorch%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/</url>
    
    <content type="html"><![CDATA[<p>本笔记从<a href="https://www.bilibili.com/video/BV1hE411t7RN/">小土堆Pytorch教程</a>中记录一些实用的Pytorch相关操作.</p><h1 id="1-加载数据"><a href="#1-加载数据" class="headerlink" title="1. 加载数据"></a>1. 加载数据</h1><h2 id="1-1-PIL"><a href="#1-1-PIL" class="headerlink" title="1.1 PIL"></a>1.1 PIL</h2><p>PIL类可以用于加载图像、保存图像等操作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br>img = Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;data/hymenoptera_data/train/ants/342438950_a3da61deab.jpg&#x27;</span>)<br></code></pre></td></tr></table></figure><h2 id="1-2-DataSet"><a href="#1-2-DataSet" class="headerlink" title="1.2 DataSet"></a>1.2 DataSet</h2><p>DataSet是一个抽象类，需要实现其中的<code>__getitem__</code>方法，以及最好是实现<code>__len__</code>方法，不然不能用迭代器，用for循环的方式取数据,<br>以下是一个自定义数据集的设置方式，可以看到需要重写<code>__getitem__</code>方法取数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyDataSet</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, data_dir, transforms=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.data_dir = data_dir<br>        <span class="hljs-variable language_">self</span>.image_paths = os.listdir(data_dir)<br>        <span class="hljs-variable language_">self</span>.transforms = transforms<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>) -&gt; T_co:<br>        img_file_name = <span class="hljs-variable language_">self</span>.image_paths[index]<br>        img = Image.<span class="hljs-built_in">open</span>(<span class="hljs-variable language_">self</span>.data_dir + img_file_name)<br>        img_trans = <span class="hljs-variable language_">self</span>.transforms(img)<br>        <span class="hljs-keyword">return</span> img_trans<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(<span class="hljs-variable language_">self</span>.image_paths)<br></code></pre></td></tr></table></figure><h2 id="1-3-DataLoader"><a href="#1-3-DataLoader" class="headerlink" title="1.3 DataLoader"></a>1.3 DataLoader</h2><p>如果把DataSet看做一副牌，那么DataLoader就是用于定义如何发牌，或者对牌进行一些操作（洗牌、转换格式等），如果已经有一个数据集，那么可以通过这种方式定义data_loader</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">my_ds = MyDataSet(data_dir=<span class="hljs-string">&#x27;data/hymenoptera_data/val/ants/&#x27;</span>, transforms=trans)<br><span class="hljs-comment"># drop_last: 总长度除bs 除不尽的时候是否去掉最后一个</span><br><span class="hljs-comment"># batch_size: 批的量</span><br>data_loader = DataLoader(dataset=my_ds, batch_size=<span class="hljs-number">2</span>, shuffle=<span class="hljs-literal">True</span>, drop_last=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><p>定义好的数据集，可以通过DataLoader加载，并通过for循环取数据，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">step = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> images <span class="hljs-keyword">in</span> data_loader:<br>    <span class="hljs-built_in">print</span>(images.shape)<br>    writer.add_images(<span class="hljs-string">&#x27;image_batch&#x27;</span>, images, step)  <span class="hljs-comment"># (tag,Image,step(不添加这个参数 tensorboard里面的step始终为零))</span><br>    step += <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><h2 id="1-4-torchvision数据集的下载和使用"><a href="#1-4-torchvision数据集的下载和使用" class="headerlink" title="1.4 torchvision数据集的下载和使用"></a>1.4 torchvision数据集的下载和使用</h2><p>如果是一些成熟的数据集，比如CIFAR10，可以用封装好的方式获取数据集，这些数据集也是重写了DataSet类，可以传入transform</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">train_data = torchvision.datasets.CIFAR10(root=<span class="hljs-string">&#x27;../data&#x27;</span>, train=<span class="hljs-literal">True</span>, transform=torchvision.transforms.ToTensor(),<br>                                          download=<span class="hljs-literal">True</span>)<br>test_data = torchvision.datasets.CIFAR10(root=<span class="hljs-string">&#x27;../data&#x27;</span>, train=<span class="hljs-literal">False</span>, transform=torchvision.transforms.ToTensor(),<br>                                         download=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><h1 id="2-Tensorboard-的使用"><a href="#2-Tensorboard-的使用" class="headerlink" title="2. Tensorboard 的使用"></a>2. Tensorboard 的使用</h1><p>TensorBoard是一个可视化工具，它可以用来展示网络图、张量的指标变化、张量的分布情况等。特别是在训练网络的时候，我们可以设置不同的参数（比如：权重W、偏置B、卷积层数、全连接层数等），使用TensorBoader可以很直观的帮我们进行参数的选择。它通过运行一个本地服务器，来监听6006端口。在浏览器发出请求时，分析训练时记录的数据，绘制训练过程中的图像。</p><p>首先定义一个SummaryWriter()，然后就可以用writer里面的方法往tensorboard里面写数据，不仅可以添加过程量还可以添加单张图像。默认的路径保存到本地runs目录下，可以用SummaryWriter()</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">writer = SummaryWriter()<br><span class="hljs-comment"># 添加过程量（标量）</span><br><span class="hljs-keyword">for</span> n_iter <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):<br>    writer.add_scalar(<span class="hljs-string">&#x27;Loss/train&#x27;</span>, np.random.random(), n_iter)<br>    writer.add_scalar(<span class="hljs-string">&#x27;Loss/test&#x27;</span>, np.random.random(), n_iter)<br>    writer.add_scalar(<span class="hljs-string">&#x27;Accuracy/train&#x27;</span>, np.random.random(), n_iter)<br>    writer.add_scalar(<span class="hljs-string">&#x27;Accuracy/test&#x27;</span>, np.random.random(), n_iter)<br>writer.add_image(tag=<span class="hljs-string">&#x27;test&#x27;</span>, img_tensor=img_tensor)<br></code></pre></td></tr></table></figure><p>查看数据：cd到保存文件的文件夹下，输入<code>tensorboard --logdir runs</code> runs对应文件保存的目录，然后就可以通过访问<code>http://localhost:6006/#timeseries</code>查看记录的结果</p><h1 id="3-Transforms-的使用"><a href="#3-Transforms-的使用" class="headerlink" title="3. Transforms 的使用"></a>3. Transforms 的使用</h1><p>Transforms用来对一张图片进行一系列的转换，可以用Compose定义需要转换的内容</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">trans = transforms.Compose([<br>    transforms.ToTensor(),<br>    <span class="hljs-comment"># transforms.RandomCrop(size=(50,50)) 随机裁剪</span><br>    transforms.Resize((<span class="hljs-number">100</span>, <span class="hljs-number">100</span>))<br>])<br><br></code></pre></td></tr></table></figure><p>定义好转换之后，可以对单张图片进行转换，把图像传入就可以，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 添加图像</span><br>img = Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;data/hymenoptera_data/train/ants/342438950_a3da61deab.jpg&#x27;</span>)<br><span class="hljs-comment"># 图像转换</span><br>trans = transforms.Compose([<br>    transforms.ToTensor(),<br>    <span class="hljs-comment"># transforms.RandomCrop(size=(50,50)) # 随机裁剪</span><br>])<br>img_tensor = trans(img)<br></code></pre></td></tr></table></figure><h1 id="4-常用函数"><a href="#4-常用函数" class="headerlink" title="4. 常用函数"></a>4. 常用函数</h1><h2 id="4-1卷积函数"><a href="#4-1卷积函数" class="headerlink" title="4.1卷积函数"></a>4.1卷积函数</h2><p>卷积函数的定义网上有很多了就不再赘述了，定义一个卷积核，然后和现在的矩阵进行卷积操作，可得到一个结果。</p><p>借用知乎<a href="https://zhuanlan.zhihu.com/p/161660908">2D卷积,nn.Conv2d和F.conv2d</a>一段话：卷积操作：卷积核和扫过的小区域对应位置相乘再求和的操作，卷积完成后一般要加个偏置bias。一种Kernel如果分成多个通道上的子Kernel做卷积运算，最后运算结果还要加在一起后，再加偏置。</p><p>使用卷积运算的时候需要注意输入输出的尺寸，需要对齐，比如Conv2D 如果是函数就要求B ,C 两个维度要对齐。<br>需要注意的点是输入输出维度会根据stride、padding的设置改变，比如64×64的图像进去，不设置padding出来的图像可能就变成62×62了，如果还要保持图像尺寸一致（特别是复现论文的场景），需要反算一下stride和padding的值，这里公式在<a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d">Pytorch Conv2d文档</a>，需要的时候直接查阅就好。</p><p>关于可视化展示卷积函数中的stride、padding、dilation参数的含义，可参考文档：<a href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md">Convolution arithmetic</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br>w = torch.rand(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>)  <span class="hljs-comment"># 对应 B C ×卷积核的 H W，前2个维度对应上（在H W两个维度上进行卷积）</span><br>res = F.conv2d(<span class="hljs-built_in">input</span>=a, weight=w, stride=<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(res)<br><br>tensor([[[[-<span class="hljs-number">0.9163</span>, -<span class="hljs-number">1.4657</span>, -<span class="hljs-number">3.6013</span>,  ...,  <span class="hljs-number">0.1913</span>, -<span class="hljs-number">1.4308</span>, -<span class="hljs-number">1.1725</span>],<br>          [-<span class="hljs-number">1.7863</span>, -<span class="hljs-number">1.1487</span>, -<span class="hljs-number">3.5197</span>,  ..., -<span class="hljs-number">0.5010</span>, -<span class="hljs-number">2.3962</span>, -<span class="hljs-number">3.8177</span>],<br>          [-<span class="hljs-number">0.0863</span>, -<span class="hljs-number">0.3723</span>, -<span class="hljs-number">1.7177</span>,  ..., -<span class="hljs-number">1.9196</span>, -<span class="hljs-number">1.4938</span>, -<span class="hljs-number">2.6761</span>],<br>          ...,<br>          [ <span class="hljs-number">0.8136</span>, -<span class="hljs-number">4.5267</span>, -<span class="hljs-number">0.6807</span>,  ..., -<span class="hljs-number">2.2519</span>,  <span class="hljs-number">1.4239</span>, -<span class="hljs-number">0.9793</span>],<br>          [ <span class="hljs-number">1.8353</span>, -<span class="hljs-number">1.8440</span>, -<span class="hljs-number">3.9382</span>,  ..., -<span class="hljs-number">1.8193</span>,  <span class="hljs-number">2.7279</span>,  <span class="hljs-number">4.4726</span>],<br>          [ <span class="hljs-number">0.5444</span>,  <span class="hljs-number">1.2673</span>, -<span class="hljs-number">3.4205</span>,  ..., -<span class="hljs-number">2.3179</span>, -<span class="hljs-number">2.5870</span>, -<span class="hljs-number">1.7544</span>]]]])<br></code></pre></td></tr></table></figure><h2 id="4-2-池化函数"><a href="#4-2-池化函数" class="headerlink" title="4.2 池化函数"></a>4.2 池化函数</h2><p>池化函数是深度学习中常用的技术，主要用于降低数据的维度和减少计算量。常见的池化函数包括：</p><ol><li>最大池化（Max Pooling）：在池化窗口内选取最大值作为输出，能够提取图像中的主要特征。</li><li>平均池化（Average Pooling）：在池化窗口内取平均值作为输出，可以平滑输入数据，减少噪声的影响。</li><li>自适应池化（Adaptive Pooling）：根据输入的大小自动调整池化窗口的大小，以适应不同的输入尺寸。</li></ol><p>池化操作可以分为一维池化、二维池化和三维池化，具体取决于被池化的张量维数。池化不仅可以减小数据大小，还可以增加数据大小，具体取决于应用场景。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">a = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">64</span>, <span class="hljs-number">64</span>)<br>res = F.max_pool2d(a,kernel_size=<span class="hljs-number">2</span>) <span class="hljs-comment"># kernel_size指定2的话是默认2×2的2d（正方形）。而且池化默认区域不重叠的，默认步长就是kernel_size=2，这一点和卷积运算不一样</span><br><span class="hljs-built_in">print</span>(res.shape) <span class="hljs-comment"># torch.Size([1, 3, 32, 32])</span><br></code></pre></td></tr></table></figure><h1 id="5-神经网络的搭建"><a href="#5-神经网络的搭建" class="headerlink" title="5. 神经网络的搭建"></a>5. 神经网络的搭建</h1><h2 id="5-1-卷积层、池化层、非线性激活层"><a href="#5-1-卷积层、池化层、非线性激活层" class="headerlink" title="5.1 卷积层、池化层、非线性激活层"></a>5.1 卷积层、池化层、非线性激活层</h2><p>通过引入<code>torch.nn</code>引入常见神经网络的层，包括卷积层、池化层等.以及非线性激活层，RELU SOFTMAX之类的，具体就不再展开了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyNeuralNetwork</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, *args, **kwargs</span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-built_in">super</span>().__init__(*args, **kwargs)<br>        <span class="hljs-variable language_">self</span>.conv1 = nn.Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">64</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>        <span class="hljs-variable language_">self</span>.conv2 = nn.Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">64</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>)<br>        <span class="hljs-variable language_">self</span>.max_pool = nn.MaxPool2d(<span class="hljs-number">4</span>)<br>        <span class="hljs-variable language_">self</span>.relu = nn.ReLU()<br>        <span class="hljs-variable language_">self</span>.softmax = nn.Softmax()<br>        <span class="hljs-comment"># in_channels: int,</span><br>        <span class="hljs-comment"># out_channels: int,</span><br>        <span class="hljs-comment"># kernel_size: _size_2_t,</span><br>        <span class="hljs-comment"># stride: _size_2_t = 1,</span><br>        <span class="hljs-comment"># padding: Union[str, _size_2_t] = 0,</span><br>        <span class="hljs-comment"># dilation: _size_2_t = 1,</span><br><br>a = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">64</span>, <span class="hljs-number">64</span>)<br><br>mnn = MyNeuralNetwork()<br><br>res_conv1 = mnn.conv1(a)<br><span class="hljs-built_in">print</span>(res_conv1.shape)  <span class="hljs-comment"># torch.Size([1, 64, 64, 64])</span><br><br>res_conv2 = mnn.conv2(a)<br><span class="hljs-built_in">print</span>(res_conv2.shape)  <span class="hljs-comment"># torch.Size([1, 64, 62, 62])</span><br><br>res_max_pool = mnn.max_pool(a)<br><span class="hljs-built_in">print</span>(res_max_pool.shape)  <span class="hljs-comment"># torch.Size([1, 3, 16, 16])</span><br><br><br></code></pre></td></tr></table></figure><h2 id="5-2线性层及其他层"><a href="#5-2线性层及其他层" class="headerlink" title="5.2线性层及其他层"></a>5.2线性层及其他层</h2><ol><li>线性层：线性层又叫全连接层，其中每个神经元和上一层所有的神经元相连，使用<code>nn.Linear(in_features,out_features,bias)</code>定义,运算公式是 $$y&#x3D;xA^T+b$$ ，注意默认是加上bias的，即<code>bias=True</code><br>代码例子：</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyNeuralNetwork</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, *args, **kwargs</span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-variable language_">self</span>.linear = nn.Linear(<span class="hljs-number">64</span>,<span class="hljs-number">32</span>)<br>a = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">64</span>, <span class="hljs-number">64</span>)<br>res_l = mnn.linear(a)<br><span class="hljs-built_in">print</span>(res_l.shape) <span class="hljs-comment"># torch.Size([1, 3, 64, 32])</span><br></code></pre></td></tr></table></figure><ol start="2"><li>展平层：将多维度的张量展平。默认参数：<code>start_dim: int = 1, end_dim: int = -1</code> 从开始的维度展开到结束的维度<br>代码例子：</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyNeuralNetwork</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, *args, **kwargs</span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-variable language_">self</span>.flatten1 = nn.Flatten(start_dim=<span class="hljs-number">0</span>)<br>        <span class="hljs-variable language_">self</span>.flatten2 = nn.Flatten()<br>a = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">64</span>, <span class="hljs-number">64</span>)<br>res_f = mnn.flatten1(a)<br>res_f2 = mnn.flatten2(a)<br><span class="hljs-built_in">print</span>(res_f.shape) <span class="hljs-comment"># torch.Size([12288])</span><br><span class="hljs-built_in">print</span>(res_f2.shape) <span class="hljs-comment"># torch.Size([1, 12288])</span><br></code></pre></td></tr></table></figure><p>一般说来，Flatten层常用于把多维的输入一维化，常用在从卷积层到全连接层的过渡。Flatten默认不影响batch的大小（start_dim &#x3D;1 ）。</p><h2 id="5-3-Sequential的使用"><a href="#5-3-Sequential的使用" class="headerlink" title="5.3 Sequential的使用"></a>5.3 Sequential的使用</h2><p>nn.Sequential() 可以作为容器，里面放入模型的各种层，在forward的时候将会贯序列执行各层，通常有2种定义方式</p><ul><li>定义方式1</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br>model = nn.Sequential(<br>                  nn.Conv2d(<span class="hljs-number">1</span>,<span class="hljs-number">20</span>,<span class="hljs-number">5</span>),<br>                  nn.ReLU(),<br>                  nn.Conv2d(<span class="hljs-number">20</span>,<span class="hljs-number">64</span>,<span class="hljs-number">5</span>),<br>                  nn.ReLU()<br>                )<br> <br><span class="hljs-built_in">print</span>(model)<br><span class="hljs-built_in">print</span>(model[<span class="hljs-number">2</span>]) <span class="hljs-comment"># 通过索引获取第几个层</span><br><span class="hljs-string">&#x27;&#x27;&#x27;运行结果为：</span><br><span class="hljs-string">Sequential(</span><br><span class="hljs-string">  (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))</span><br><span class="hljs-string">  (1): ReLU()</span><br><span class="hljs-string">  (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))</span><br><span class="hljs-string">  (3): ReLU()</span><br><span class="hljs-string">)</span><br><span class="hljs-string">Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><ul><li>定义方式2：给每个层添加一个名称</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> OrderedDict<br>model = nn.Sequential(OrderedDict([<br>                  (<span class="hljs-string">&#x27;conv1&#x27;</span>, nn.Conv2d(<span class="hljs-number">1</span>,<span class="hljs-number">20</span>,<span class="hljs-number">5</span>)),<br>                  (<span class="hljs-string">&#x27;relu1&#x27;</span>, nn.ReLU()),<br>                  (<span class="hljs-string">&#x27;conv2&#x27;</span>, nn.Conv2d(<span class="hljs-number">20</span>,<span class="hljs-number">64</span>,<span class="hljs-number">5</span>)),<br>                  (<span class="hljs-string">&#x27;relu2&#x27;</span>, nn.ReLU())<br>                ]))<br> <br><span class="hljs-built_in">print</span>(model)<br><span class="hljs-string">&#x27;&#x27;&#x27;运行结果为：</span><br><span class="hljs-string">Sequential(</span><br><span class="hljs-string">  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))</span><br><span class="hljs-string">  (relu1): ReLU()</span><br><span class="hljs-string">  (conv2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))</span><br><span class="hljs-string">  (relu2): ReLU()</span><br><span class="hljs-string">)</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><p>我们可以将前面所学的层组合起来，形成深层神经网络的架构，例如我们可以编写一个自己的网络如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyNeuralNetwork</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, *args, **kwargs</span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-built_in">super</span>().__init__(*args, **kwargs)<br>        <span class="hljs-variable language_">self</span>.model = nn.Sequential(<br>            nn.Conv2d(<span class="hljs-number">3</span>,<span class="hljs-number">64</span>,<span class="hljs-number">3</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>),  <span class="hljs-comment"># 【1,64,64,64】 备注：ks=3，stride=1，padding = 1</span><br>            <span class="hljs-comment"># Hout(64) = (Hin(64) + 2×padding - dilation×[ks - 1] × 1 )/stride + 1</span><br>            nn.ReLU(),<br>            nn.Conv2d(<span class="hljs-number">64</span>,<span class="hljs-number">32</span>,<span class="hljs-number">3</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>),  <span class="hljs-comment"># 1,32,64,64</span><br>            nn.ReLU(),<br>            nn.Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">16</span>, <span class="hljs-number">3</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>), <span class="hljs-comment"># 1,16,64,64</span><br>            nn.ReLU(),<br>            nn.MaxPool2d(<span class="hljs-number">2</span>), <span class="hljs-comment"># 1,16,32,32</span><br>            nn.ReLU(),<br>            nn.Linear(<span class="hljs-number">32</span>,<span class="hljs-number">1024</span>), <span class="hljs-comment"># 1,16,32,1024</span><br>            nn.ReLU(),<br>            nn.Linear(<span class="hljs-number">1024</span>, <span class="hljs-number">1024</span>),  <span class="hljs-comment"># 1,16,1024,1024</span><br>            nn.ReLU(),<br>            nn.Flatten(), <span class="hljs-comment"># 1,524288</span><br>            nn.Linear(<span class="hljs-number">524288</span>,<span class="hljs-number">10</span>),  <span class="hljs-comment"># 1,10</span><br>            nn.Softmax(dim= -<span class="hljs-number">1</span>)<br>        )<br><br>mnn = MyNeuralNetwork()<br><br>a = torch.randn(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">64</span>,<span class="hljs-number">64</span>)<br><br>res = mnn.model(a)<br><br><span class="hljs-built_in">print</span>(res.shape) <span class="hljs-comment"># torch.Size([1, 10])</span><br><span class="hljs-built_in">print</span>(res) <span class="hljs-comment">#tensor([[0.0991, 0.0982, 0.0997, 0.0996, 0.1009, 0.1030, 0.0988, 0.1027, 0.0991,0.0988]], grad_fn=&lt;SoftmaxBackward0&gt;)</span><br></code></pre></td></tr></table></figure><p>通过使用Sequential()的方式可以便捷的完成网络的定义，快速实现网络。</p><h2 id="5-4-小网络搭建实战"><a href="#5-4-小网络搭建实战" class="headerlink" title="5.4 小网络搭建实战"></a>5.4 小网络搭建实战</h2><p>以vgg16这个网络（图待补充）为例，搭建模型如下（暂未添加Relu层），其实和我们之前写的模型很像</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyNeuralNetwork</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, *args, **kwargs</span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-built_in">super</span>().__init__(*args, **kwargs)<br>        <span class="hljs-variable language_">self</span>.model= nn.Sequential(<br>            nn.Conv2d(<span class="hljs-number">3</span>,<span class="hljs-number">32</span>,<span class="hljs-number">5</span>,padding=<span class="hljs-number">2</span>),<br>            nn.MaxPool2d(<span class="hljs-number">2</span>),<br>            nn.Conv2d(<span class="hljs-number">32</span>,<span class="hljs-number">32</span>,<span class="hljs-number">5</span>,padding=<span class="hljs-number">2</span>),<br>            nn.MaxPool2d(<span class="hljs-number">2</span>),<br>            nn.Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">64</span>, <span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>),<br>            nn.MaxPool2d(<span class="hljs-number">2</span>),<br>            nn.Flatten(),<br>            nn.Linear(<span class="hljs-number">4096</span>,<span class="hljs-number">64</span>),<br>            nn.Linear(<span class="hljs-number">64</span>, <span class="hljs-number">10</span>),<br>        )<br><br>a = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">64</span>, <span class="hljs-number">64</span>)<br>mnn = MyNeuralNetwork()<br>res = mnn.model(a)<br><span class="hljs-built_in">print</span>(res.shape) <span class="hljs-comment">#torch.Size([1, 10])</span><br></code></pre></td></tr></table></figure><h1 id="6-损失函数与反向传播"><a href="#6-损失函数与反向传播" class="headerlink" title="6 损失函数与反向传播"></a>6 损失函数与反向传播</h1><h2 id="6-1-损失函数"><a href="#6-1-损失函数" class="headerlink" title="6.1 损失函数"></a>6.1 损失函数</h2><p>损失函数（Loss Function）是一个衡量预测结果与真实结果之间差异的函数 ，也称为误差函数。它通过计算模型的预测值与真实值之间的不一致程度，来评估模型的性能.<br>根据任务不同，选择的损失函数也不同，对于回归任务，常见的损失函数有<code>MSELoss</code>,对于分类任务常见的损失函数有交叉熵损失<code>CrossEntropyLoss</code><br>交叉熵的损失函数可以描述为 $$loss(x,class) &#x3D; -log(exp(x[class]&#x2F;sum_j(exp(x[j])))&#x3D;-x[class]+ln(sum_j(exp(x[j])]))$$<br>举例说明：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br>x = torch.tensor([[<span class="hljs-number">0.1</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.3</span>]]) <span class="hljs-comment"># 预测三个类别概率分别是0.1,0.2,0.3</span><br>y = torch.tensor([<span class="hljs-number">1</span>]) <span class="hljs-comment"># 答案是1</span><br>loss = F.cross_entropy(x, y) <span class="hljs-comment"># 计算交叉熵 loss = -0.2 + ln(e^0.1+e^0.2+e^0.3) = 1.10194284823</span><br><span class="hljs-built_in">print</span>(loss) <span class="hljs-comment"># tensor(1.1019)</span><br></code></pre></td></tr></table></figure><p>其他的案例也差不多</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">x = torch.tensor([[<span class="hljs-number">0.55</span>, <span class="hljs-number">0.88</span>]]) <span class="hljs-comment"># 预测值</span><br>y = torch.tensor([[<span class="hljs-number">0.5</span>, <span class="hljs-number">0.8</span>]]) <span class="hljs-comment"># 真实值</span><br>loss_l1 = F.l1_loss(x, y) <span class="hljs-comment"># L1Loss 一阶距</span><br>loss_mse = F.mse_loss(x, y) <span class="hljs-comment"># MSE_LOSS</span><br><span class="hljs-built_in">print</span>(loss_l1) <span class="hljs-comment"># tensor(0.0650)</span><br><span class="hljs-built_in">print</span>(loss_mse) <span class="hljs-comment"># tensor(0.0044)</span><br><br>loss_layer = nn.L1Loss(reduction=<span class="hljs-string">&#x27;sum&#x27;</span>)  <span class="hljs-comment"># 备注：reduction默认是mean，用mean的话结果是0.065</span><br>loss_l1_by_layer = loss_layer(x, y)<br><span class="hljs-built_in">print</span>(loss_l1_by_layer)  <span class="hljs-comment"># tensor(0.1300)</span><br></code></pre></td></tr></table></figure><h2 id="6-2-反向传播"><a href="#6-2-反向传播" class="headerlink" title="6.2 反向传播"></a>6.2 反向传播</h2><p>首先说一下什么是反向传播算法。<br>反向传播算法(Backpropagation，简称BP算法)是“误差反向传播”的简称，是适合于多层神经元网络的一种学习算法，它建立在梯度下降法的基础上。梯度下降法是训练神经网络的常用方法，许多的训练方法都是基于梯度下降法改良出来的，因此了解梯度下降法很重要。梯度下降法通过计算损失函数的梯度，并将这个梯度反馈给最优化函数来更新权重以最小化损失函数。</p><p>在PyTorch中，loss.backward()函数用于计算模型参数相对于损失函数的梯度。</p><p>前向传播</p><p>首先，模型通过前向传播计算输出值。在这个过程中，PyTorch会记录计算图（Computation Graph），这个计算图记录了从输入到输出的每一步运算及其依赖关系。每个张量（Tensor）都有一个.grad_fn属性，指向一个函数，这个函数描述了如何计算这个张量关于其输入的梯度。</p><p>反向传播</p><p>当调用loss.backward()时，PyTorch开始反向遍历计算图。这个过程从损失函数开始，沿着图反向传播误差，计算每一个参与运算的张量关于损失的梯度。这是通过链式法则（Chain Rule）完成的，即将损失对某个中间变量的导数分解为其后续操作导数的乘积。</p><p>梯度计算<br>在反向传播过程中，每个运算都会计算其输出关于输入的梯度，并将这个梯度累积到输入张量的.grad属性中（如果是标量损失，它没有.grad属性）。这意味着如果一个张量被多个路径使用，它的.grad属性会累积从所有路径来的梯度.</p><p>在使用loss.backward()时，有几个重要的注意事项：</p><pre><code class="hljs">梯度归零：在每次反向传播之前，通常需要调用optimizer.zero_grad()来将梯度归零，以避免梯度累加</code></pre><h2 id="6-3-优化器"><a href="#6-3-优化器" class="headerlink" title="6.3 优化器"></a>6.3 优化器</h2><p>优化器决定了模型以何种方式的梯度下降算法更新模型。常见的优化器有 SGD, adam等。</p><p>在PyTorch中，optimizer.step()是优化器对象的一个方法，用于执行模型参数的更新。在深度学习训练过程中，参数更新是通过反向传播算法计算损失函数的梯度后，使用优化器根据这些梯度进行的。optimizer.step()方法正是用于根据梯度和学习率等超参数来更新模型参数，从而使损失函数值最小化的步骤</p><h1 id="7-使用常用模型"><a href="#7-使用常用模型" class="headerlink" title="7 使用常用模型"></a>7 使用常用模型</h1><h2 id="7-1-使用库的方式调用常用模型"><a href="#7-1-使用库的方式调用常用模型" class="headerlink" title="7.1 使用库的方式调用常用模型"></a>7.1 使用库的方式调用常用模型</h2><p>一些常用的模型，比较经典的模型都是包装在库里面了，可以通过<code>torchvision.models.xxx</code>调用模型.<br>例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python">vgg16 = torchvision.models.vgg16(pretrained = <span class="hljs-literal">False</span>)<br><br><span class="hljs-built_in">print</span>(vgg16)<br><br>输出：<br>VGG(<br>  (features): Sequential(<br>    (<span class="hljs-number">0</span>): Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">64</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    (<span class="hljs-number">1</span>): ReLU(inplace=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">2</span>): Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">64</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    (<span class="hljs-number">3</span>): ReLU(inplace=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">4</span>): MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">0</span>, dilation=<span class="hljs-number">1</span>, ceil_mode=<span class="hljs-literal">False</span>)<br>    (<span class="hljs-number">5</span>): Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    (<span class="hljs-number">6</span>): ReLU(inplace=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">7</span>): Conv2d(<span class="hljs-number">128</span>, <span class="hljs-number">128</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    (<span class="hljs-number">8</span>): ReLU(inplace=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">9</span>): MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">0</span>, dilation=<span class="hljs-number">1</span>, ceil_mode=<span class="hljs-literal">False</span>)<br>    (<span class="hljs-number">10</span>): Conv2d(<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    (<span class="hljs-number">11</span>): ReLU(inplace=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">12</span>): Conv2d(<span class="hljs-number">256</span>, <span class="hljs-number">256</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    (<span class="hljs-number">13</span>): ReLU(inplace=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">14</span>): Conv2d(<span class="hljs-number">256</span>, <span class="hljs-number">256</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    (<span class="hljs-number">15</span>): ReLU(inplace=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">16</span>): MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">0</span>, dilation=<span class="hljs-number">1</span>, ceil_mode=<span class="hljs-literal">False</span>)<br>    (<span class="hljs-number">17</span>): Conv2d(<span class="hljs-number">256</span>, <span class="hljs-number">512</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    (<span class="hljs-number">18</span>): ReLU(inplace=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">19</span>): Conv2d(<span class="hljs-number">512</span>, <span class="hljs-number">512</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    (<span class="hljs-number">20</span>): ReLU(inplace=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">21</span>): Conv2d(<span class="hljs-number">512</span>, <span class="hljs-number">512</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    (<span class="hljs-number">22</span>): ReLU(inplace=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">23</span>): MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">0</span>, dilation=<span class="hljs-number">1</span>, ceil_mode=<span class="hljs-literal">False</span>)<br>    (<span class="hljs-number">24</span>): Conv2d(<span class="hljs-number">512</span>, <span class="hljs-number">512</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    (<span class="hljs-number">25</span>): ReLU(inplace=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">26</span>): Conv2d(<span class="hljs-number">512</span>, <span class="hljs-number">512</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    (<span class="hljs-number">27</span>): ReLU(inplace=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">28</span>): Conv2d(<span class="hljs-number">512</span>, <span class="hljs-number">512</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    (<span class="hljs-number">29</span>): ReLU(inplace=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">30</span>): MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">0</span>, dilation=<span class="hljs-number">1</span>, ceil_mode=<span class="hljs-literal">False</span>)<br>  )<br>  (avgpool): AdaptiveAvgPool2d(output_size=(<span class="hljs-number">7</span>, <span class="hljs-number">7</span>))<br>  (classifier): Sequential(<br>    (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">25088</span>, out_features=<span class="hljs-number">4096</span>, bias=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">1</span>): ReLU(inplace=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0.5</span>, inplace=<span class="hljs-literal">False</span>)<br>    (<span class="hljs-number">3</span>): Linear(in_features=<span class="hljs-number">4096</span>, out_features=<span class="hljs-number">4096</span>, bias=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">4</span>): ReLU(inplace=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">5</span>): Dropout(p=<span class="hljs-number">0.5</span>, inplace=<span class="hljs-literal">False</span>)<br>    (<span class="hljs-number">6</span>): Linear(in_features=<span class="hljs-number">4096</span>, out_features=<span class="hljs-number">1000</span>, bias=<span class="hljs-literal">True</span>)<br>  )<br>)<br><br></code></pre></td></tr></table></figure><h2 id="7-2-对常用模型进行增加或修改"><a href="#7-2-对常用模型进行增加或修改" class="headerlink" title="7.2 对常用模型进行增加或修改"></a>7.2 对常用模型进行增加或修改</h2><ol><li>增加某层</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">vgg16.features.add_module(<span class="hljs-string">&#x27;relu&#x27;</span>,torch.nn.ReLU())<br>vgg16.classifier.add_module(<span class="hljs-string">&#x27;linear&#x27;</span>,torch.nn.Linear(<span class="hljs-number">1000</span>,<span class="hljs-number">10</span>))<br>例如分类器加上之后，模型结构如下：<br>  (classifier): Sequential(<br>    (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">25088</span>, out_features=<span class="hljs-number">4096</span>, bias=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">1</span>): ReLU(inplace=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0.5</span>, inplace=<span class="hljs-literal">False</span>)<br>    (<span class="hljs-number">3</span>): Linear(in_features=<span class="hljs-number">4096</span>, out_features=<span class="hljs-number">4096</span>, bias=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">4</span>): ReLU(inplace=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">5</span>): Dropout(p=<span class="hljs-number">0.5</span>, inplace=<span class="hljs-literal">False</span>)<br>    (<span class="hljs-number">6</span>): Linear(in_features=<span class="hljs-number">4096</span>, out_features=<span class="hljs-number">1000</span>, bias=<span class="hljs-literal">True</span>)<br>    (linear): Linear(in_features=<span class="hljs-number">1000</span>, out_features=<span class="hljs-number">10</span>, bias=<span class="hljs-literal">True</span>)<br>  )<br></code></pre></td></tr></table></figure><ol start="2"><li>修改某层</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">vgg16.classifier[<span class="hljs-number">7</span>]=nn.Linear(<span class="hljs-number">1000</span>,<span class="hljs-number">20</span>) <span class="hljs-comment"># 7 是模型的第几层</span><br><br>上面的代码执行之后会对刚添加的线性层修改输出特征节点的个数，改成了<span class="hljs-number">55</span>个<br>  (classifier): Sequential(<br>    (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">25088</span>, out_features=<span class="hljs-number">4096</span>, bias=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">1</span>): ReLU(inplace=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0.5</span>, inplace=<span class="hljs-literal">False</span>)<br>    (<span class="hljs-number">3</span>): Linear(in_features=<span class="hljs-number">4096</span>, out_features=<span class="hljs-number">4096</span>, bias=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">4</span>): ReLU(inplace=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">5</span>): Dropout(p=<span class="hljs-number">0.5</span>, inplace=<span class="hljs-literal">False</span>)<br>    (<span class="hljs-number">6</span>): Linear(in_features=<span class="hljs-number">4096</span>, out_features=<span class="hljs-number">1000</span>, bias=<span class="hljs-literal">True</span>)<br>    (linear): Linear(in_features=<span class="hljs-number">1000</span>, out_features=<span class="hljs-number">55</span>, bias=<span class="hljs-literal">True</span>)<br>  )<br></code></pre></td></tr></table></figure><ol start="3"><li>删除某层<br>如果想删除某一层,直接将其删除即可，命令为</li></ol><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-selector-tag">del</span> vgg16<span class="hljs-selector-class">.classifier</span><span class="hljs-selector-attr">[7]</span><br></code></pre></td></tr></table></figure><ol start="4"><li>冻结部分层<br>我们现在只想训练最后的fc1层，然后就有了下面的</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 冻结fc1层的参数</span><br><span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> model.named_parameters():<br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;fc1&quot;</span> <span class="hljs-keyword">in</span> name:<br>        param.requires_grad = <span class="hljs-literal">False</span><br><br><span class="hljs-comment"># 只传入需要更新的参数给优化器</span><br>optimizer = optim.SGD(<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> p: p.requires_grad, model.parameters()), lr=<span class="hljs-number">1e-2</span>)<br></code></pre></td></tr></table></figure><h1 id="8-完整的训练流程"><a href="#8-完整的训练流程" class="headerlink" title="8 完整的训练流程"></a>8 完整的训练流程</h1><p>包括数据集准备，dataLoader准备、网络构建、损失函数定义、循环、计算误差、tensorboard可视化等</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><br>train_data = torchvision.datasets.CIFAR10(root=<span class="hljs-string">&#x27;/data&#x27;</span>, train=<span class="hljs-literal">True</span>, transform=torchvision.transforms.ToTensor(),<br>                                          download=<span class="hljs-literal">True</span>)<br>test_data = torchvision.datasets.CIFAR10(root=<span class="hljs-string">&#x27;/data&#x27;</span>, train=<span class="hljs-literal">False</span>, transform=torchvision.transforms.ToTensor(),<br>                                         download=<span class="hljs-literal">True</span>)<br><br>train_data_size = <span class="hljs-built_in">len</span>(train_data)<br>test_data_size = <span class="hljs-built_in">len</span>(test_data)<br><br>train_data_loader = DataLoader(train_data, batch_size=<span class="hljs-number">64</span>)<br>test_data_loader = DataLoader(test_data, batch_size=<span class="hljs-number">64</span>)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyNeuralNetwork</span>(nn.Module):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, *args, **kwargs</span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-built_in">super</span>().__init__(*args, **kwargs)<br>        <span class="hljs-variable language_">self</span>.model = nn.Sequential(<br>            nn.Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">32</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>),<br>            nn.MaxPool2d(<span class="hljs-number">2</span>),<br>            nn.Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>),<br>            nn.MaxPool2d(<span class="hljs-number">2</span>),<br>            nn.Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">64</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>),<br>            nn.MaxPool2d(<span class="hljs-number">2</span>),<br>            nn.Flatten(),<br>            nn.Linear(<span class="hljs-number">64</span> * <span class="hljs-number">4</span> * <span class="hljs-number">4</span>, <span class="hljs-number">64</span>),<br>            nn.Linear(<span class="hljs-number">64</span>, <span class="hljs-number">10</span>)<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.model(x)<br><br><br>mnn = MyNeuralNetwork()<br><span class="hljs-keyword">if</span> torch.cuda.is_available():<br>    mnn = mnn.cuda()<br><br>loss_fn = nn.CrossEntropyLoss()<br>loss_fn = loss_fn.cuda()<br><br>lr = <span class="hljs-number">1e-2</span><br>optim = torch.optim.SGD(mnn.parameters(), lr=lr)<br><br>writer = SummaryWriter(<span class="hljs-string">&#x27;../logs_train&#x27;</span>)<br>epoch = <span class="hljs-number">10</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epoch):<br>    mnn.train()<br>    train_step = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> train_data_loader:<br>        imgs, targets = data<br>        imgs = imgs.cuda()<br>        targets = targets.cuda()<br>        outputs = mnn(imgs)<br>        loss = loss_fn(outputs, targets)<br><br>        optim.zero_grad()<br>        loss.backward()<br>        optim.step()<br><br>        train_step = train_step + <span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> train_step % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;训练次数：&#123;&#125;，loss = &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(train_step, loss.item()))<br>            writer.add_scalar(<span class="hljs-string">&quot;train_loss&quot;</span>, loss.item(), train_step)<br><br>    mnn.<span class="hljs-built_in">eval</span>()<br>    total_test_loss = <span class="hljs-number">0</span><br>    total_accuracy = <span class="hljs-number">0</span><br>    total_test_step = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br><br>        <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> test_data_loader:<br>            imgs, targets = data<br>            imgs = imgs.cuda()<br>            targets = targets.cuda()<br>            outputs = mnn(imgs)<br>            loss = loss_fn(outputs, targets)<br>            total_test_loss += loss.item()<br>            <span class="hljs-comment"># 求正确率</span><br>            accuracy = (outputs.argmax(<span class="hljs-number">1</span>) == targets).<span class="hljs-built_in">sum</span>()<br>            total_accuracy += accuracy<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;整体测试集上的loss:&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(total_test_loss))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;整体测试集上的正确率:&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(total_accuracy / test_data_size))<br>    writer.add_scalar(<span class="hljs-string">&quot;test_loss&quot;</span>, total_test_loss, total_test_step)<br>    writer.add_scalar(<span class="hljs-string">&quot;test_accuracy&quot;</span>, total_accuracy / test_data_size, total_test_step)<br>    total_test_step = total_test_step + <span class="hljs-number">1</span><br><br>    <span class="hljs-comment"># 保存模型</span><br>    torch.save(mnn, <span class="hljs-string">&quot;mnn&#123;&#125;.pth&quot;</span>.<span class="hljs-built_in">format</span>(i))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;模型已保存&quot;</span>)<br><br>writer.close()<br><br></code></pre></td></tr></table></figure><p>运行代码的效果：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs text">训练次数：100，loss = 2.2861804962158203<br>训练次数：200，loss = 2.2651848793029785<br>训练次数：300，loss = 2.2193050384521484<br>训练次数：400，loss = 2.1087183952331543<br>训练次数：500，loss = 2.0523011684417725<br>训练次数：600，loss = 1.9955447912216187<br>训练次数：700，loss = 1.9990053176879883<br>整体测试集上的loss:319.1352970600128<br>整体测试集上的正确率:0.2669000029563904<br>模型已保存<br></code></pre></td></tr></table></figure><h1 id="8-1-使用GPU训练"><a href="#8-1-使用GPU训练" class="headerlink" title="8.1 使用GPU训练"></a>8.1 使用GPU训练</h1><p>除了8.1的方式在所有张量用<code>.cuda()</code>送入显存的方式使用GPU训练外，还可以用<code>tensor.to(device)</code>的方式送入显存</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">device = <span class="hljs-string">&#x27;cuda&#x27;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;cpu&#x27;</span><br><br>net = Net().to(device)<br>imgs = imgs.to(device)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Run&#39;s Studio 重新出发</title>
    <link href="/2025/03/31/hello-world/"/>
    <url>/2025/03/31/hello-world/</url>
    
    <content type="html"><![CDATA[<pre><code class="hljs">原先网站的source因为换电脑的缘故没有保存，只能重新开一份博客，记录工作中的心得体会~</code></pre>]]></content>
    
    
    <categories>
      
      <category>杂谈</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>安装和配置Pytorch和cuda</title>
    <link href="/2025/03/16/%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AEPytorch%E5%92%8Ccuda/"/>
    <url>/2025/03/16/%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AEPytorch%E5%92%8Ccuda/</url>
    
    <content type="html"><![CDATA[<h1 id="安装方法"><a href="#安装方法" class="headerlink" title="安装方法"></a>安装方法</h1><p>请参考：<a href="https://www.cnblogs.com/tryhardwy/p/14659131.html">https://www.cnblogs.com/tryhardwy/p/14659131.html</a></p><ol><li>卸载掉旧版本torch torchvision</li><li>先到（<a href="https://pytorch.org/get-started/locally/%EF%BC%89%E6%9F%A5%E5%88%B0%E7%A8%B3%E5%AE%9A%E7%89%88%E6%9C%ACtorch%E5%AF%B9%E5%BA%94%E7%9A%84cuda">https://pytorch.org/get-started/locally/）查到稳定版本torch对应的cuda</a></li><li>下载并安装cuda</li><li>到（<a href="https://pytorch.org/get-started/locally/%EF%BC%89%E6%8C%89%E7%85%A7%E5%AF%B9%E5%BA%94%E7%89%88%E6%9C%AC%E5%AE%89%E8%A3%85torch">https://pytorch.org/get-started/locally/）按照对应版本安装torch</a></li><li>安装完成后，进入python验证。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br>torch.__version__<br>torch.cuda.is_available()<br></code></pre></td></tr></table></figure><p>显示True则安装成功。</p><h1 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h1><p>注意：直接粘贴</p><p><code>pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/torch_stable.html</code> ，安装的是cpu版！</p><p>带cuda版本正确的安装语句是：</p><p><code>pip3 install torch==2.6.0+cu118 torchvision==0.21.0+cu118 --index-url https://download.pytorch.org/whl/cu118</code></p><p>如果上述地址下载太慢，还可以换用国内源例如aliyun（备注：阿里云的torch版本不全，部分最新版本无法下载，经过实验2.1.0版本可以下载并安装）<br><code>pip install torch==2.1.0+cu118 --use-deprecated=legacy-resolver  --no-cache-dir -f https://mirrors.aliyun.com/pytorch-wheels/cu118</code></p><p>其他的包 如果国内地址下载太慢，可以用以下常用镜像：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs awk">常见镜像源<br><br>清华：https:<span class="hljs-regexp">//</span>pypi.tuna.tsinghua.edu.cn<span class="hljs-regexp">/simple/</span><br>阿里云：http:<span class="hljs-regexp">//mi</span>rrors.aliyun.com<span class="hljs-regexp">/pypi/</span>simple/<br>中国科技大学：https:<span class="hljs-regexp">//</span>pypi.mirrors.ustc.edu.cn<span class="hljs-regexp">/simple/</span><br>华中科技大学：http:<span class="hljs-regexp">//</span>pypi.hustunique.com<span class="hljs-regexp">/simple/</span><br>上海交通大学：https:<span class="hljs-regexp">//mi</span>rror.sjtu.edu.cn<span class="hljs-regexp">/pypi/</span>web<span class="hljs-regexp">/simple/</span><br></code></pre></td></tr></table></figure><p>如果使用不带https的连接，还需要加上<code>--trusted-host mirrors.xxx.com</code><br>例如<br><code>pip install numpy&lt;=2.0.0 -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com</code></p>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Hexo新建博客并上传Github全流程</title>
    <link href="/2025/03/04/hexo%E6%96%B0%E5%BB%BA%E6%93%8D%E4%BD%9C%E5%B9%B6%E4%B8%8A%E4%BC%A0%E6%B5%81%E7%A8%8B/"/>
    <url>/2025/03/04/hexo%E6%96%B0%E5%BB%BA%E6%93%8D%E4%BD%9C%E5%B9%B6%E4%B8%8A%E4%BC%A0%E6%B5%81%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="step-1-安装node-js和git环境"><a href="#step-1-安装node-js和git环境" class="headerlink" title="step 1. 安装node.js和git环境"></a>step 1. 安装node.js和git环境</h1><p>可参考教程<a href="https://blog.csdn.net/suwyer/article/details/125562473%60">node和git的安装以及环境配置 (Windows)</a></p><h1 id="step-2-安装hexo"><a href="#step-2-安装hexo" class="headerlink" title="step 2. 安装hexo"></a>step 2. 安装hexo</h1><p>此时已经安装好了node.js和git，下面开始hexo的安装<br>首先在某一磁盘目录下创建文件夹，例如F盘，创建文件夹名为 Blog<br>进入Blog文件夹，右键鼠标-&gt;选择<code>Git Bash Here</code><br>输入 <code>npm install -g hexo-cli</code> ，并耐心等待一段时间<br>输入 <code>npm install hexo -save</code>，也耐心等待一段时间<br>此时我们可以发现，在Blog文件夹中多了许多内容<br>在Blog文件夹中新建文件夹，命名为hexo<br>关闭当前Git Bash，进入hexo文件夹，右键鼠标-&gt;选择Git Bash Here，或者直接在当前的Git Bash中输入 cd hexo<br>输入hexo init，初始化hexo环境，耐心等待一段时间<br>输入npm install，安装npm依赖包，耐心等待一段时间<br>输入hexo generate或者是hexo g，生成静态页面，耐心等待一段时间<br>输入hexo server或者是hexo s，生成本地服务。我们每次写完博客后，可以先在本地预览一下看看有没有什么问题，然后再发布到网上。<br>接着，我们在浏览器中访问<a href="http://localhost:4000/%EF%BC%8C%E8%BF%99%E5%B0%B1%E6%98%AF%E5%9C%A8%E6%9C%AC%E5%9C%B0%E7%94%9F%E6%88%90%E7%9A%84%E4%B8%80%E4%B8%AA%E5%8D%9A%E5%AE%A2%E3%80%82">http://localhost:4000/，这就是在本地生成的一个博客。</a><br>在Git Bash中按下Ctrl+C，可以关闭当前端口服务。</p><p>到这里，我们的本地博客就已经搭建完成了。下面将介绍如何与Github连接，将博客上传Internet</p><h1 id="step-3-新建Github仓库"><a href="#step-3-新建Github仓库" class="headerlink" title="step 3. 新建Github仓库"></a>step 3. 新建Github仓库</h1><p>登录到自己的Github中，新建一个仓库，命名为username.github.io，其中的username是你的用户名，勾选Initialiaze this repository with a README，创建仓库<br>我们可以访问自己的<code>username.github.io</code><br>返回<code>username.github.io</code>的仓库中，复制Git地址</p><h1 id="step-4-本地操作"><a href="#step-4-本地操作" class="headerlink" title="step 4.本地操作"></a>step 4.本地操作</h1><p>我们在<code>/Blog/hexo/</code>文件夹中，找到<code>_config.yml</code>文件，用文本编辑器打开它<br>将最下面的deploy改为下图所示的内容，其中repo的地址就是刚才我们复制的Git地址，修改好后保存退出 【注】修改内容中的:和后面的字母之间要有一个空格，否则后续内容会报错<br>接下来，我们暂且不考虑新建文章，在<code>Git Bash</code>中执行<code>npm install hexo-deployer-git </code>–save命令，耐心等待一段时间<br>最后执行 <code>hexo deploy</code>或者<code>hexo d</code>【注】这一步需要保证Github上拥有本机的公钥，可以自行查找解决办法<br>最后，成功部署</p><h1 id="step-5-上传博客"><a href="#step-5-上传博客" class="headerlink" title="step 5.上传博客"></a>step 5.上传博客</h1><h2 id="新建文章"><a href="#新建文章" class="headerlink" title="新建文章"></a>新建文章</h2><p>在Git Bash中输入<code>hexo new title</code>，其中，title就是我们这篇文章的名字。我们可以看到，在\Blog\hexo\source_posts\ 文件夹中新建了一个名称为<code>Test1.md</code>的文件<br>我们去编辑一下这个文件，此处需要Linux的部分知识，可以自行上网查找<br>编辑结束后，保存退出</p><h2 id="上传"><a href="#上传" class="headerlink" title="上传"></a>上传</h2><p>使用hexo g，生成静态文件<br>使用hexo d来将文档部署到Github上<br>最后我们访问username.github.io，发现刚才编辑的文档已经成功发布到了Internet上面<br>————————————————</p><p>版权声明：本文为博主原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接和本声明。</p><p>原文链接：<a href="https://blog.csdn.net/qq_43669381/article/details/107823432">https://blog.csdn.net/qq_43669381/article/details/107823432</a></p><p>部署流程（带图版）：<a href="https://blog.csdn.net/clearloe/article/details/139879493">https://blog.csdn.net/clearloe/article/details/139879493</a></p><h2 id="乱码问题解决方法"><a href="#乱码问题解决方法" class="headerlink" title="乱码问题解决方法"></a>乱码问题解决方法</h2><p>需要注意：如果本地部署没有出现乱码，但是主题上传到github上可能出现乱码，排版不正常的情况，此时要修改 <code>__config.yaml</code> 文件,修改：<br>url: <a href="https://yourpage.github.io/">https://yourpage.github.io</a> （自己的主页的网址，最后不要有&#x2F;）<br>root: &#x2F;   （增加这一行）<br>保存后重新生成并部署即可正常显示。</p><h3 id="使用vscode更改粘贴图片默认位置"><a href="#使用vscode更改粘贴图片默认位置" class="headerlink" title="使用vscode更改粘贴图片默认位置"></a>使用vscode更改粘贴图片默认位置</h3><pre><code class="hljs">点击小齿轮，打开设置输入 markdown.copy, 找到 Markdown&gt; Copy Files:Destination新增项, Key为: **/*.md, value为目标路径：assets/$&#123;documentBaseName&#125;/$&#123;fileName&#125;</code></pre>]]></content>
    
    
    <categories>
      
      <category>常用知识</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
